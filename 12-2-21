from requests.models import Response
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import bs4
from bs4 import BeautifulSoup
import requests
import webbrowser
import sys
import pandas as pd
import html5lib
from selenium.common.exceptions import NoSuchCookieException, NoSuchElementException
from selenium.webdriver.support.ui import Select
from time import sleep
import numpy as np
import os
import urllib.request
from selenium.common.exceptions import *

username = os.getlogin()
options = webdriver.ChromeOptions()
driver = webdriver.Chrome(
    options=options, executable_path=r'C:/Users/' + username + '/mypythonscripts/chromedriver')
options.add_experimental_option("excludeSwitches", ["enable-logging"])
options.add_experimental_option("detach", True)
#Runs selenium in the background
#options.add_argument('headless')
list_of_links = []
filtered_list = []
price_list = []
def main():
    #page = requests.get('https://www.google.com/')
    #page.raise_for_status()


    
    #Goes to URL home page
    driver.get('https://www.google.com/search?q=allintext%3A926482-001+site%3Aebay.com&rlz=1C1CHBF_enUS902US902&oq=allintext%3A926482-001+site%3Aebay.com&aqs=chrome..69i57j69i58.793j0j15&sourceid=chrome&ie=UTF-8')
    wait = WebDriverWait(driver, 30)
    #Search_bar = driver.find_element_by_name(
    #    "q")

    #Inputs part number and vendor site in search box
    #Search_bar.send_keys("allintext:926482-001 site:ebay.com", Keys.ENTER)

    get_href_link_list()
    sleep(2)
    #print(list_of_links)
    #sort_ebay_links()
    #sleep(2)
    #print()
    
    

    


def get_href_link_list():
    soup = BeautifulSoup(driver.page_source, features='lxml')
    for a_tag in soup.find_all('a'):
        href_list = [(a_tag.get('href'))]
        list_of_links.append(str(href_list))
        return list_of_links
        
def sort_ebay_links():
    new_list = [s[14:18] for s in list_of_links]
    print(new_list)
    # creates a list idx_list and enumerates a list of substringed values from list_of_links
    # if ebay is in list it appends the index to idx_list.
     # assigns new_list index values
    idx_list = []
    for idx, item in enumerate(new_list):
            if "ebay" in item:
                idx_list.append(f"{idx}")
    # Finds the start and end of the indexes that have the proper links that will be needed for a range call.
    idx_range_start = int(idx_list[0])
    idx_range_end = int(idx_list[-1])
    #list_of_href_links_to_click = list_of_links[idx_range_start:idx_range_end]
    print(idx_list)
    #print(list_of_links[idx_range_start:idx_range_end])
    #print(list_of_href_links_to_click)
    #for cite_tag in driver.find_elements_by_tag_name("cite"):
    #    getEbayPrice(cite_tag)
        #cite_tag.click()
        #url = driver.current_url
        #return getEbayPrice(url)

        #sleep(4)
        #getEbayPrice(driver.current_url)
    #cite_tags = driver.find_element_by_tag_name("cite")
    #print(cite_tags)
    #for link in cite_tags:
     #   print(link)       
      #  wait = WebDriverWait(driver, 10)
       # WebDriverWait(driver, 20).until(EC.visibility_of_element_located(
        #    (cite_tags, link))).click()


def getEbayPrice(productUrl):
    res = requests.get(productUrl)
    res.raise_for_status()
    soup = bs4.BeautifulSoup(res.text, 'html.parser')
    selector1 = (bool(soup.select('#prcIsum')))
    selector2 = (bool(soup.select(
        '#s0-0-18-5-12-26-50 > div > span.item-price > div')))
    if selector1 == True:
        elems = soup.select('#prcIsum')
    elif selector2 == True:
        elems = soup.select(
            '#s0-0-18-5-12-26-50 > div > span.item-price > div')
    return elems[0].text.strip()


#price = getEbayPrice(
   # 'https://www.ebay.com/p/28022853255')
#print("The price is: " + price)
main()
sleep(2)
driver.close()
