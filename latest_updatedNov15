from typing import Pattern
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import re
import bs4
import requests
import webbrowser
import sys
import pyperclip
import pandas as pd
from selenium.common.exceptions import NoSuchCookieException, NoSuchElementException
from selenium.webdriver.support.ui import Select
from time import sleep
#8cg7222dcd
page = requests.get('https://partsurfer.hp.com/Search.aspx')
page.raise_for_status()


# Asks user for serial number
print('enter serial number')
serial_number = input()
print('enter item description')
item = input().upper()

keywords = [item]
#print(type(keywords))

options = webdriver.ChromeOptions()
options.add_experimental_option("excludeSwitches", ["enable-logging"])
#options.page_load_strategy = 'eager'
options.add_argument('headless')
driver = webdriver.Chrome(
    options=options, executable_path=r'C:/Users/biven/mypythonscripts/chromedriver')

driver.get('https://partsurfer.hp.com/Search.aspx')
#driver.manage().window().maximize()
wait = WebDriverWait(driver, 3)

select = Select(driver.find_element_by_name(
    'ctl00$BodyContentPlaceHolder$ddlCountry'))
select.select_by_visible_text('United States')

element = wait.until(EC.element_to_be_clickable(
    (By.XPATH, "// *[@id='onetrust-accept-btn-handler']"))).click()

#alert = driver.switch_to.alert

textElem = driver.find_element_by_name(
    "ctl00$BodyContentPlaceHolder$SearchText$TextBox1")
textElem.send_keys(serial_number)
textElem.submit()
searchElem = driver.find_element_by_xpath(
    "//*[@id='ctl00_BodyContentPlaceHolder_SearchText_btnSubmit']").click()

soup = bs4.BeautifulSoup(driver.page_source, features="lxml")
tables = soup.find_all(
    'table', {"id": ["ctl00_BodyContentPlaceHolder_gridSpareBOM"]})
#print(type(tables))

#rows = soup.find_all("td", "title")

table = tables[0]
tab_data = [[cell.text for cell in row.find_all(["th", "td"])]
            for row in table.find_all("tr")]
print(tab_data)
print(len(tab_data))
#print(type(tab_data))
thislist = tab_data
#print(type(thislist))
#test3 = soup.find(string='BACK COVER, LCD NSV')
#test3 = soup.find(string=re.compile("L??"))
#print(test3)
#print(test3)
#print(test3.find_parent("td"))
test4 = soup.find(string='926482-001')
#print(test4)
#print(test4.find_parent('td'))

pattern = re.compile('LCD')

test5 = soup.table
#print(test5)
#test 5 value
#test5v = print(test5.find_next_siblings("table"))
#print(test5)
#print(type(test5v))
#test = soup.find_all('tr', {'id': re.findall(r'LCD')})
#print(test)
# Grabs part page current url and turns it into html


url2 = driver.current_url
print(url2)

req1 = requests.get(url2)
if req1.status_code in [200]:
    html_doc = req1.text
else:
    print('Could not retrieve: % s, err: % s - status code: % s' %
          (url2, req1.text, req1.status_code))
#print(html_doc)

soup1 = bs4.BeautifulSoup(html_doc, 'html.parser')
#print(soup1.prettify())
#print(soup1.get_text())
tag1 = soup1.td
#print(type(tag1))
#print(tag1.name)
#tag2 = bs4.BeautifulSoup(html_doc, 'html.parser').td
#print(tag2['title'])
#soup1.table.

#for tag in soup1.find_all(re.compile("^[A-Za-z]*$", "td")):
#    print(tag.name)
#for table in soup1.table:
#    print(table)
#re.match("^[A-Za-z]*$", "LCD")
#print(soup1.table)
#print(soup1.find_all('table'))
#for child in soup1.:
#    print(tag.con)
#testA = print(soup1.table)

#partPageHtml = urlopen(url2)

#partPage = bs4.BeautifulSoup(html_doc, 'html.parser')
#print(partPage.prettify())
#test2 = soup.find_all(['tr', 'td'])
#print(type(test2))

#for tag in soup.find_all(True):
#    print(tag.name)
#print(type(thislist))

#for line in thislist:
#    for word in keywords:
#        if word in line:
#            print(line)
#            break

#print(thislist)
#m = re.match(r"(\w+) (\w+)", )
#m.group(0)
#m.group(1)

#print(thislist[1])
#vector = tab_data
#L = [text for list in vector for text in list]
#print(L)
#for lists in tab_data:
#    for list in lists:
#        for text in list:
#            print(text[0:7], end=' ')
#print(len(thislist))


#df = pd.DataFrame(tab_data)
#df.columns = df.iloc[0, :]
#df.drop(index=0, inplace=True)

#tabs_dic = {}

#for table in tables:
#    tab_name = table['id']

#    tab_data = [[cell.text for cell in row.find_all(["th", "td"])]
#                for row in table.find_all("tr")]
#    df = pd.DataFrame(tab_data)
#    df.columns = df.iloc[0, :]
#    df.drop(index=0, inplace=True)

#df = df.loc[df.Season != ""]
#    tabs_dic[tab_name] = df
sleep(2)
#https://stackoverflow.com/questions/23580726/python-beautifulsoup-list-index-after-the-table
#https://www.crummy.com/software/BeautifulSoup/bs4/doc/
driver.close()
